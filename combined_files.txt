
=== ./middleware.ts ===
import { clerkMiddleware, createRouteMatcher } from "@clerk/nextjs/server";

const isPublicRoute = createRouteMatcher(["/sign-in(.*)", "/sign-up(.*)"]);

export default clerkMiddleware((auth, request) => {
  if (!isPublicRoute(request)) {
    auth().protect();
  }
});

export const config = {
  matcher: [
    // Skip Next.js internals and all static files, unless found in search params
    "/((?!_next|[^?]*\\.(?:html?|css|js(?!on)|jpe?g|webp|png|gif|svg|ttf|woff2?|ico|csv|docx?|xlsx?|zip|webmanifest)).*)",
    // Always run for API routes
    "/(api|trpc)(.*)",
  ],
};


=== ./Biomefile ===
{
  "name": "confetto"
}

=== ./combined_files.txt ===


=== ./postcss.config.mjs ===
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;


=== ./next.config.mjs ===
/** @type {import('next').NextConfig} */
const nextConfig = {};

export default nextConfig;


=== ./next-env.d.ts ===
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.


=== ./README.md ===
# Confetto - AI-Powered MMI Interview Prep

## Product Requirements Document (PRD)

### Table of Contents

1. [Introduction](#1-introduction)
2. [Objectives and Goals](#2-objectives-and-goals)
3. [Target Audience](#3-target-audience)
4. [Product Overview](#4-product-overview)
   4.1 [Features](#41-features)
   4.2 [User Stories](#42-user-stories)
5. [Technical Requirements](#5-technical-requirements)
   5.1 [Architecture](#51-architecture)
   5.2 [Database Schema](#52-database-schema)
   5.3 [Data Flow](#53-data-flow)
6. [Pages and User Interface](#6-pages-and-user-interface)
   6.1 [Page Descriptions](#61-page-descriptions)
   6.2 [Wireframes (Optional)](#62-wireframes-optional)

### 1. Introduction

The AI-Powered MMI Interview Prep App is designed to assist medical school applicants in preparing for Multiple Mini Interviews (MMIs) by simulating realistic interview scenarios using artificial intelligence. The app provides an interactive platform where users can practice responding to MMI questions, receive comprehensive scoring, and obtain detailed feedback to improve their performance.

### 2. Objectives and Goals

**Primary Objective:** To create an accessible and effective tool that enhances the MMI preparation process for medical school applicants.

**Goals:**

- Simulate realistic MMI interview scenarios using AI.
- Provide personalized scoring and feedback based on user responses.
- Track user progress over time to highlight improvements.
- Ensure a user-friendly interface that is intuitive and engaging.

### 3. Target Audience

- **Primary Users:** Individuals preparing for medical school admissions who will undergo MMI interviews.
- **Secondary Users:** Pre-med advisors, educational institutions offering preparatory courses, and coaching professionals.

### 4. Product Overview

#### 4.1 Features

1. **AI-Simulated MMI Questions:**

   - Randomized selection from a vast question bank.
   - Covers various categories like ethical dilemmas, situational judgments, and policy discussions.

2. **Recording and Interactive Response:**

   - Users record their responses (up to 5 minutes).
   - Optional AI-driven back-and-forth interaction simulating an interviewer.

3. **Scoring System:**

   - Comprehensive scoring out of 100.
   - Breakdown into key categories:
     - Communication Skills
     - Critical Thinking
     - Ethical Reasoning
     - Professionalism

4. **Detailed Feedback:**

   - Highlights strengths and areas for improvement.
   - Provides actionable advice for enhancement.

5. **Progress Tracking:**

   - History of past sessions.
   - Visual representation of performance over time.

6. **User Authentication and Profile Management:**

   - Secure sign-up and login via Clerk.js.
   - Personalized dashboard and settings.

#### 4.2 User Stories

1. As a user, I want to practice MMI questions so that I can prepare for my medical school interviews.
2. As a user, I want to receive detailed feedback on my responses so that I know where to improve.
3. As a user, I want to track my progress over time so that I can see how I am improving.
4. As a user, I want a user-friendly interface so that I can focus on my preparation without technical difficulties.

### 5. Technical Requirements

#### 5.1 Architecture

- **Frontend:** Next.js with the App Router and server components.
- **UI Framework:** React with Shadcn UI, Radix UI, and Tailwind CSS for styling.
- **Authentication:** Clerk.js for user authentication and session management.
- **Backend:** Prisma ORM connected to a PostgreSQL database.
- **AI Services:**
  - **Speech-to-Text:** Transcribe user recordings using a service like Google Cloud Speech-to-Text API.
  - **Natural Language Processing (NLP):** Analyze transcripts, score responses, and generate feedback using OpenAI's GPT-4 API.
- **Storage:**
  - **Cloud Storage:** Firebase Storage for storing audio recordings.
- **State Management:**
  - Utilize React's built-in state and context APIs, minimize use of client-side state where possible.
- **Performance Optimization:**
  - Implement server-side rendering (SSR) and static site generation (SSG) where appropriate.
  - Optimize images and assets for web performance.

#### 5.2 Database Schema

The database schema is defined using Prisma ORM and includes the following models:

- **User**

  ```prisma
  model User {
    id               Int               @id @default(autoincrement())
    name             String
    email            String            @unique
    practiceSessions PracticeSession[]
    createdAt        DateTime          @default(now())
    updatedAt        DateTime          @updatedAt
  }
  ```

- **Question**

  ```prisma
  model Question {
    id               Int               @id @default(autoincrement())
    content          String
    category         String
    practiceSessions PracticeSession[]
    createdAt        DateTime          @default(now())
    updatedAt        DateTime          @updatedAt
  }
  ```

- **PracticeSession**

  ```prisma
  model PracticeSession {
    id                Int             @id @default(autoincrement())
    user              User            @relation(fields: [userId], references: [id])
    userId            Int
    question          Question        @relation(fields: [questionId], references: [id])
    questionId        Int
    startTime         DateTime
    endTime           DateTime?
    recordingUrl      String?
    transcript        String?
    score             Score?
    feedback          Feedback?
    createdAt         DateTime        @default(now())
    updatedAt         DateTime        @updatedAt
  }
  ```

- **Score**

  ```prisma
  model Score {
    id                Int             @id @default(autoincrement())
    practiceSession   PracticeSession @relation(fields: [practiceSessionId], references: [id])
    practiceSessionId Int             @unique
    totalScore        Float
    categoryScores    Json
    createdAt         DateTime        @default(now())
    updatedAt         DateTime        @updatedAt
  }
  ```

- **Feedback**

  ```prisma
  model Feedback {
    id                Int             @id @default(autoincrement())
    practiceSession   PracticeSession @relation(fields: [practiceSessionId], references: [id])
    practiceSessionId Int             @unique
    content           String
    createdAt         DateTime        @default(now())
    updatedAt         DateTime        @updatedAt
  }
  ```

#### 5.3 Data Flow

1. **User Authentication:**

   - User signs up or logs in via Clerk.js.
   - Authentication tokens are securely managed.

2. **Session Initiation:**

   - User navigates to start a new practice session.
   - A random question is fetched from the PostgreSQL database using Prisma.

3. **Recording Response:**

   - User records their response using the Web Audio API.
   - Audio file is uploaded to Firebase Storage.

4. **Transcription:**

   - The audio URL is sent to the Speech-to-Text service.
   - Transcribed text is saved to the database.

5. **NLP Analysis:**

   - Transcribed text is sent to the NLP service (e.g., GPT-4).
   - Service returns a scoring object and feedback.
   - Score and feedback are saved in the database associated with the practice session.

6. **Displaying Results:**

   - User is redirected to the results page.
   - Scores and feedback are fetched from the database and displayed.

7. **Progress Tracking:**
   - User's practice sessions are aggregated to show progress over time.
   - Data visualization components display the user's improvement.

### 6. Pages and User Interface

#### 6.1 Page Descriptions

1. **Home Page:**

   - **URL:** `/`
   - **Description:** Introduces the app with a compelling hero section, feature highlights, and testimonials. Contains call-to-action buttons for sign-up and login.

2. **Sign-Up / Login Page:**

   - **URL:** `/sign-in`
   - **Description:** Utilizes Clerk.js components for user authentication. Provides options for email/password and social logins.

3. **Dashboard:**

   - **URL:** `/dashboard`
   - **Description:** Displays user statistics, recent practice sessions, and a button to start a new session. Shows progress charts using dynamic data.

4. **Practice Session Page:**

   - **URL:** `/session`
   - **Description:** Presents the MMI question and a recorder interface. Includes a timer and guidelines. Users can start, pause, and stop recording.

5. **Results Page:**

   - **URL:** `/session/results`
   - **Description:** Shows the user's score with a breakdown by category. Displays detailed AI-generated feedback and the transcribed response.

6. **Profile Settings Page:**

   - **URL:** `/profile`
   - **Description:** Allows users to update personal information, change passwords, and set preferences.

7. **History Page:**

   - **URL:** `/history`
   - **Description:** Lists all past practice sessions with dates and scores. Users can click on a session to view detailed results.

8. **Error Page:**

   - **URL:** `/error`
   - **Description:** Generic error handling page that informs the user of any issues and provides navigation options.

#### 6.2 Wireframes (Optional)

While wireframes are optional at this stage, they can be created using tools like Figma or Sketch to provide visual guidance for the UI/UX design.

**Note:** Ensure that all pages are responsive and adhere to accessibility standards. Use Tailwind CSS for consistent styling and Radix UI components for interactive elements like modals and dropdowns.


=== ./tailwind.config.ts ===
import type { Config } from "tailwindcss";

const config: Config = {
    darkMode: ["class"],
    content: [
    "./pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./components/**/*.{js,ts,jsx,tsx,mdx}",
    "./app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
  	extend: {
  		colors: {
  			background: 'hsl(var(--background))',
  			foreground: 'hsl(var(--foreground))',
  			card: {
  				DEFAULT: 'hsl(var(--card))',
  				foreground: 'hsl(var(--card-foreground))'
  			},
  			popover: {
  				DEFAULT: 'hsl(var(--popover))',
  				foreground: 'hsl(var(--popover-foreground))'
  			},
  			primary: {
  				DEFAULT: 'hsl(var(--primary))',
  				foreground: 'hsl(var(--primary-foreground))'
  			},
  			secondary: {
  				DEFAULT: 'hsl(var(--secondary))',
  				foreground: 'hsl(var(--secondary-foreground))'
  			},
  			muted: {
  				DEFAULT: 'hsl(var(--muted))',
  				foreground: 'hsl(var(--muted-foreground))'
  			},
  			accent: {
  				DEFAULT: 'hsl(var(--accent))',
  				foreground: 'hsl(var(--accent-foreground))'
  			},
  			destructive: {
  				DEFAULT: 'hsl(var(--destructive))',
  				foreground: 'hsl(var(--destructive-foreground))'
  			},
  			border: 'hsl(var(--border))',
  			input: 'hsl(var(--input))',
  			ring: 'hsl(var(--ring))',
  			chart: {
  				'1': 'hsl(var(--chart-1))',
  				'2': 'hsl(var(--chart-2))',
  				'3': 'hsl(var(--chart-3))',
  				'4': 'hsl(var(--chart-4))',
  				'5': 'hsl(var(--chart-5))'
  			}
  		},
  		borderRadius: {
  			lg: 'var(--radius)',
  			md: 'calc(var(--radius) - 2px)',
  			sm: 'calc(var(--radius) - 4px)'
  		}
  	}
  },
  plugins: [require("tailwindcss-animate")],
};
export default config;


=== ./package.json ===
{
  "name": "confetto-next",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "d": "next dev",
    "build": "next build",
    "dp": "npx prisma db push",
    "g": "npx prisma generate",
    "sd": "npx prisma studio",
    "start": "next start",
    "format": "biome format .",
    "lint": "biome check .",
    "postinstall": "npx prisma generate"
  },
  "dependencies": {
    "@clerk/nextjs": "^5.7.1",
    "@radix-ui/react-slot": "^1.1.0",
    "@radix-ui/react-toast": "^1.2.2",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.1",
    "firebase": "^10.14.0",
    "highlight.js": "^11.10.0",
    "lucide-react": "^0.447.0",
    "next": "14.2.14",
    "openai": "^4.67.1",
    "posthog-js": "^1.166.1",
    "react": "^18",
    "react-dom": "^18",
    "react-markdown": "^9.0.1",
    "replicate": "^0.34.1",
    "tailwind-merge": "^2.5.3",
    "tailwindcss-animate": "^1.0.7"
  },
  "devDependencies": {
    "@prisma/client": "^5.20.0",
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "biome": "^0.3.3",
    "postcss": "^8",
    "prisma": "^5.20.0",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}


=== ./components.json ===
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  }
}

=== ./tsconfig.json ===
{
  "compilerOptions": {
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}


=== ./biome.json ===
{
  "$schema": "https://biomejs.dev/schemas/1.9.3/schema.json",
  "vcs": {
    "enabled": false,
    "clientKind": "git",
    "useIgnoreFile": false
  },
  "files": {
    "ignoreUnknown": false,
    "ignore": [".next/**", "node_modules/**"]
  },
  "formatter": { "enabled": true, "indentStyle": "tab" },
  "organizeImports": { "enabled": true },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true,
      "complexity": {
        "noForEach": "off"
      }
    }
  },
  "javascript": { "formatter": { "quoteStyle": "double" } }
}


=== ./concat_files.py ===
import os
from typing import List


def concat_files_to_txt(
    root_dir: str,
    output_file: str,
    exclude_dirs: List[str] = None,
    exclude_files: List[str] = None,
) -> None:
    """
    Concatenates all files in the specified directory into a single text file,
    excluding specified directories and files.

    Args:
        root_dir (str): The root directory to traverse.
        output_file (str): The path to the output text file.
        exclude_dirs (List[str], optional): List of directory names to exclude.
                                           Defaults to ['node_modules', '.next'].
        exclude_files (List[str], optional): List of file names to exclude.
                                            Defaults to ['.env', 'pnpm-lock.yaml'].
    """
    if exclude_dirs is None:
        exclude_dirs = ["node_modules", ".next"]
    if exclude_files is None:
        exclude_files = [".env", "pnpm-lock.yaml"]

    with open(output_file, "w", encoding="utf-8") as outfile:
        for dirpath, dirnames, filenames in os.walk(root_dir):
            # Modify dirnames in-place to skip excluded directories
            dirnames[:] = [
                d for d in dirnames if d not in exclude_dirs and not d.startswith(".")
            ]

            for filename in filenames:
                file_path = os.path.join(dirpath, filename)

                # Skip excluded files and hidden files
                if filename in exclude_files or filename.startswith("."):
                    continue

                try:
                    with open(file_path, "r", encoding="utf-8") as infile:
                        outfile.write(f"\n=== {file_path} ===\n")
                        outfile.write(infile.read())
                        outfile.write("\n")
                except (UnicodeDecodeError, PermissionError):
                    # Skip files that can't be read as text
                    continue


def main():
    root_directory = "."  # Replace with your project directory if different
    output_path = "combined_files.txt"
    excluded_directories = ["node_modules", ".next"]
    excluded_files = [".env", "pnpm-lock.yaml"]

    concat_files_to_txt(
        root_dir=root_directory,
        output_file=output_path,
        exclude_dirs=excluded_directories,
        exclude_files=excluded_files,
    )
    print(f"All files have been concatenated into {output_path}")


if __name__ == "__main__":
    main()


=== ./app/favicon.ico ===

=== ./app/layout.tsx ===
import type { Metadata } from "next";
import { ClerkProvider } from "@clerk/nextjs";
import "./globals.css";
import { auth } from "@clerk/nextjs/server";
import { prisma } from "@/lib/prisma";
import { CSPostHogProvider } from "../components/CSPostHogProvider";
import { Toaster } from "@/components/ui/toaster";

export const metadata: Metadata = {
  title: "Confetto - AI-Powered MMI Interview Prep",
  description:
    "Enhance your medical school interview skills with our AI-driven Multiple Mini Interview (MMI) preparation platform. Practice realistic scenarios, receive personalized feedback, and track your progress.",
};

export default async function RootLayout({ children }: { children: React.ReactNode }) {
  const userId = auth().userId;

  if (userId) {
    const user = await prisma.user.findUnique({
      where: { id: userId },
    });

    if (!user) {
      await prisma.user.create({
        data: { id: userId },
      });
    }
  }

  return (
    <html lang="en">
      <body>
        <CSPostHogProvider>
          <ClerkProvider>
            {children}
            <Toaster />
          </ClerkProvider>
        </CSPostHogProvider>
      </body>
    </html>
  );
}


=== ./app/page.tsx ===
import { Button } from "@/components/ui/button";
import { SignOutButton, UserButton } from "@clerk/nextjs";

export default function Home() {
  return (
    <div className="p-4">
      <div className="flex justify-between items-center">
        <Button>Create Session</Button>
        <UserButton />
      </div>
    </div>
  );
}


=== ./app/globals.css ===
@tailwind base;
@tailwind components;
@tailwind utilities;
@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 0 0% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 0 0% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 0 0% 3.9%;
    --primary: 0 0% 9%;
    --primary-foreground: 0 0% 98%;
    --secondary: 0 0% 96.1%;
    --secondary-foreground: 0 0% 9%;
    --muted: 0 0% 96.1%;
    --muted-foreground: 0 0% 45.1%;
    --accent: 0 0% 96.1%;
    --accent-foreground: 0 0% 9%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 89.8%;
    --input: 0 0% 89.8%;
    --ring: 0 0% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem
  }
  .dark {
    --background: 0 0% 3.9%;
    --foreground: 0 0% 98%;
    --card: 0 0% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 0 0% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 0 0% 9%;
    --secondary: 0 0% 14.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 0 0% 14.9%;
    --muted-foreground: 0 0% 63.9%;
    --accent: 0 0% 14.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 14.9%;
    --input: 0 0% 14.9%;
    --ring: 0 0% 83.1%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%
  }
}
@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}


=== ./app/sign-up/[[...sign-up]]/page.tsx ===
import { SignUp } from "@clerk/nextjs";

export default function Page() {
  return (
    <div className="flex items-center justify-center min-h-screen">
      <SignUp />
    </div>
  );
}


=== ./app/create-session/page.tsx ===
import { prisma } from "@/lib/prisma";
import { Button } from "@/components/ui/button";
import { redirect } from "next/navigation";
import { auth } from "@clerk/nextjs/server";
import { createMockSession } from "@/lib/actions";

export default async function CreateSessionPage() {
  const questions = await prisma.question.findMany();
  const userId = auth().userId;

  if (!userId) {
    redirect("/sign-in");
  }

  return (
    <div className="container mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Create Session</h1>
      <ul className="space-y-2">
        {questions.map((question) => (
          <li
            key={question.id}
            className="p-2 bg-gray-100 rounded flex justify-between items-center"
          >
            <p className="font-semibold">{question.content}</p>
            <form action={createMockSession}>
              <input type="hidden" name="questionId" value={question.id} />
              <input type="hidden" name="userId" value={userId} />
              <Button type="submit">Start Mock Interview</Button>
            </form>
          </li>
        ))}
      </ul>
    </div>
  );
}


=== ./app/sign-in/[[...sign-in]]/page.tsx ===
import { SignIn } from "@clerk/nextjs";

export default function Page() {
  return (
    <div className="flex items-center justify-center min-h-screen">
      <SignIn />
    </div>
  );
}


=== ./app/fonts/GeistMonoVF.woff ===

=== ./app/fonts/GeistVF.woff ===

=== ./app/session/[sessionId]/page.tsx ===
import MicButton from "@/components/MicButton";
import { notFound } from "next/navigation";
import { prisma } from "@/lib/prisma";
import { MarkdownRenderer } from "@/components/MarkdownRenderer";
import AudioPlayer from "@/components/AudioPlayer";

export default async function SessionPage({ params }: { params: { sessionId: string } }) {
  const { sessionId } = params;

  if (!sessionId) {
    notFound();
  }

  const practiceSession = await prisma.practiceSession.findUnique({
    where: { id: sessionId },
    include: { question: true, feedback: true },
  });

  if (!practiceSession || !practiceSession.question) {
    notFound();
  }

  const question = practiceSession.question.content;
  const feedback = practiceSession.feedback?.content;
  const transcription = practiceSession.recordingTranscription;
  const recordingUrl = practiceSession.recordingUrl;

  return (
    <div className="container mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Session Question:</h1>
      <p className="text-lg mb-6">{question}</p>
      <div className="mt-8">
        <MicButton sessionId={sessionId} />
      </div>
      {recordingUrl && (
        <div className="mt-4">
          <h2 className="text-xl font-bold mb-2">Recording:</h2>
          <AudioPlayer src={recordingUrl} />
        </div>
      )}
      {transcription && (
        <div className="mt-4">
          <h2 className="text-xl font-bold mb-2">Transcription:</h2>
          <p className="text-lg">{transcription}</p>
        </div>
      )}
      {feedback && (
        <div className="mt-8">
          <h2 className="text-xl font-bold mb-2">Feedback:</h2>
          <MarkdownRenderer content={feedback} />
        </div>
      )}
    </div>
  );
}


=== ./prisma/schema.prisma ===
generator client {
    provider = "prisma-client-js"
}

datasource db {
    provider = "postgresql" // or your preferred database
    url      = env("DATABASE_URL")
}

//this is basically just to link between ClerkUserID and Prisma DB
model User {
    id               String            @id @default(uuid())
    practiceSessions PracticeSession[]
}

model Question {
    id               String            @id @default(uuid())
    content          String
    practiceSessions PracticeSession[]
    createdAt        DateTime          @default(now())
    updatedAt        DateTime          @updatedAt
}

model PracticeSession {
    id                     String    @id @default(uuid())
    user                   User      @relation(fields: [userId], references: [id])
    userId                 String
    question               Question  @relation(fields: [questionId], references: [id])
    questionId             String
    recordingUrl           String?
    recordingTranscription String?
    feedback               Feedback?

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt
}

model Feedback {
    id                String          @id @default(uuid())
    content           String
    practiceSession   PracticeSession @relation(fields: [practiceSessionId], references: [id])
    practiceSessionId String          @unique
    createdAt         DateTime        @default(now())
    updatedAt         DateTime        @updatedAt
}


=== ./components/AudioPlayer.tsx ===
"use client";

import { useState, useRef, useEffect } from "react";

interface AudioPlayerProps {
  src: string;
}

export default function AudioPlayer({ src }: AudioPlayerProps) {
  const [isPlaying, setIsPlaying] = useState(false);
  const [duration, setDuration] = useState(0);
  const [currentTime, setCurrentTime] = useState(0);
  const audioRef = useRef<HTMLAudioElement>(null);

  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const setAudioData = () => {
      setDuration(audio.duration);
      setCurrentTime(audio.currentTime);
    };

    const setAudioTime = () => setCurrentTime(audio.currentTime);

    audio.addEventListener("loadedmetadata", setAudioData);
    audio.addEventListener("timeupdate", setAudioTime);

    return () => {
      audio.removeEventListener("loadedmetadata", setAudioData);
      audio.removeEventListener("timeupdate", setAudioTime);
    };
  }, []);

  const togglePlayPause = () => {
    const audio = audioRef.current;
    if (!audio) return;

    if (isPlaying) {
      audio.pause();
    } else {
      audio.play();
    }
    setIsPlaying(!isPlaying);
  };

  const formatTime = (time: number) => {
    if (Number.isNaN(time) || !Number.isFinite(time)) return "0:00";
    const minutes = Math.floor(time / 60);
    const seconds = Math.floor(time % 60);
    return `${minutes}:${seconds.toString().padStart(2, "0")}`;
  };

  return (
    <div className="flex items-center space-x-4">
      <audio ref={audioRef} src={src}>
        <track kind="captions" />
      </audio>
      <button
        type="button"
        onClick={togglePlayPause}
        className="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded"
      >
        {isPlaying ? "Pause" : "Play"}
      </button>
      <div className="text-sm">
        {formatTime(currentTime)} / {formatTime(duration)}
      </div>
    </div>
  );
}


=== ./components/CSPostHogProvider.tsx ===
// app/providers.js
"use client";
import posthog from "posthog-js";
import { PostHogProvider } from "posthog-js/react";

if (typeof window !== "undefined") {
  const posthogKey = process.env.NEXT_PUBLIC_POSTHOG_KEY;
  const posthogHost = process.env.NEXT_PUBLIC_POSTHOG_HOST;

  if (posthogKey && posthogHost) {
    posthog.init(posthogKey, {
      api_host: posthogHost,
      person_profiles: "identified_only", // or 'always' to create profiles for anonymous users as well
    });
  } else {
    console.warn("PostHog initialization failed: Missing key or host");
  }
}

export function CSPostHogProvider({ children }: { children: React.ReactNode }) {
  return <PostHogProvider client={posthog}>{children}</PostHogProvider>;
}


=== ./components/MicButton.tsx ===
"use client";

import { useState, useRef, useCallback, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Mic, Square } from "lucide-react";
import { uploadAudioToFirebase } from "@/lib/firebase";
import { saveAudioUrl } from "@/lib/actions";

interface MicButtonProps {
  sessionId: string;
}

export default function MicButton({ sessionId }: MicButtonProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [timer, setTimer] = useState(0);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerIntervalRef = useRef<NodeJS.Timeout | null>(null);

  useEffect(() => {
    return () => {
      if (timerIntervalRef.current) {
        clearInterval(timerIntervalRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start();
      setIsRecording(true);
      setTimer(0);
      timerIntervalRef.current = setInterval(() => {
        setTimer((prevTimer) => prevTimer + 1);
      }, 1000);
    } catch (error) {
      console.error("Error starting recording:", error);
      alert("Microphone access is required to record audio.");
    }
  }, []);

  const stopRecording = useCallback(async () => {
    if (mediaRecorderRef.current && isRecording) {
      return new Promise<void>((resolve) => {
        if (mediaRecorderRef.current) {
          mediaRecorderRef.current.onstop = async () => {
            if (chunksRef.current.length > 0) {
              const audioBlob = new Blob(chunksRef.current, { type: "audio/webm" });
              try {
                const url = await uploadAudioToFirebase(audioBlob, sessionId);
                console.log("Audio uploaded successfully:", url);
                await saveAudioUrl(url, sessionId);
              } catch (error) {
                console.error("Error uploading audio:", error);
              }
            } else {
              console.log("No audio data recorded");
            }
            resolve();
          };
        }

        mediaRecorderRef.current?.stop();
        setIsRecording(false);
        if (timerIntervalRef.current) {
          clearInterval(timerIntervalRef.current);
        }
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((track) => track.stop());
        }
      });
    }
  }, [isRecording, sessionId]);

  const toggleRecording = async () => {
    if (isRecording) {
      await stopRecording();
    } else {
      await startRecording();
    }
  };

  const formatTime = (seconds: number) => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes.toString().padStart(2, "0")}:${remainingSeconds.toString().padStart(2, "0")}`;
  };

  return (
    <div className="flex flex-col items-center">
      <Button
        onClick={toggleRecording}
        variant={isRecording ? "destructive" : "default"}
        size="icon"
        className="w-16 h-16 rounded-full"
      >
        {isRecording ? <Square className="h-8 w-8" /> : <Mic className="h-8 w-8" />}
      </Button>
      {isRecording && <span className="mt-2 text-sm font-medium">{formatTime(timer)}</span>}
    </div>
  );
}


=== ./components/MarkdownRenderer.tsx ===
"use client";

import React from "react";
import ReactMarkdown from "react-markdown";

interface MarkdownRendererProps {
  content: string;
}

export function MarkdownRenderer({ content }: MarkdownRendererProps) {
  return <ReactMarkdown>{content}</ReactMarkdown>;
}


=== ./components/ui/toaster.tsx ===
"use client"

import { useToast } from "@/hooks/use-toast"
import {
  Toast,
  ToastClose,
  ToastDescription,
  ToastProvider,
  ToastTitle,
  ToastViewport,
} from "@/components/ui/toast"

export function Toaster() {
  const { toasts } = useToast()

  return (
    <ToastProvider>
      {toasts.map(function ({ id, title, description, action, ...props }) {
        return (
          <Toast key={id} {...props}>
            <div className="grid gap-1">
              {title && <ToastTitle>{title}</ToastTitle>}
              {description && (
                <ToastDescription>{description}</ToastDescription>
              )}
            </div>
            {action}
            <ToastClose />
          </Toast>
        )
      })}
      <ToastViewport />
    </ToastProvider>
  )
}


=== ./components/ui/button.tsx ===
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50",
  {
    variants: {
      variant: {
        default: "bg-primary text-primary-foreground hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground hover:bg-destructive/90",
        outline:
          "border border-input bg-background hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-10 px-4 py-2",
        sm: "h-9 rounded-md px-3",
        lg: "h-11 rounded-md px-8",
        icon: "h-10 w-10",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }


=== ./components/ui/toast.tsx ===
"use client"

import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const ToastProvider = ToastPrimitives.Provider

const ToastViewport = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Viewport>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Viewport
    ref={ref}
    className={cn(
      "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
      className
    )}
    {...props}
  />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName

const toastVariants = cva(
  "group pointer-events-auto relative flex w-full items-center justify-between space-x-4 overflow-hidden rounded-md border p-6 pr-8 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
  {
    variants: {
      variant: {
        default: "border bg-background text-foreground",
        destructive:
          "destructive group border-destructive bg-destructive text-destructive-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Toast = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
  return (
    <ToastPrimitives.Root
      ref={ref}
      className={cn(toastVariants({ variant }), className)}
      {...props}
    />
  )
})
Toast.displayName = ToastPrimitives.Root.displayName

const ToastAction = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Action>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Action
    ref={ref}
    className={cn(
      "inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium ring-offset-background transition-colors hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
      className
    )}
    {...props}
  />
))
ToastAction.displayName = ToastPrimitives.Action.displayName

const ToastClose = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Close>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Close
    ref={ref}
    className={cn(
      "absolute right-2 top-2 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-2 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
      className
    )}
    toast-close=""
    {...props}
  >
    <X className="h-4 w-4" />
  </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName

const ToastTitle = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Title>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Title
    ref={ref}
    className={cn("text-sm font-semibold", className)}
    {...props}
  />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName

const ToastDescription = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Description>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Description
    ref={ref}
    className={cn("text-sm opacity-90", className)}
    {...props}
  />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>

type ToastActionElement = React.ReactElement<typeof ToastAction>

export {
  type ToastProps,
  type ToastActionElement,
  ToastProvider,
  ToastViewport,
  Toast,
  ToastTitle,
  ToastDescription,
  ToastClose,
  ToastAction,
}


=== ./hooks/use-toast.ts ===
"use client"

// Inspired by react-hot-toast library
import * as React from "react"

import type {
  ToastActionElement,
  ToastProps,
} from "@/components/ui/toast"

const TOAST_LIMIT = 1
const TOAST_REMOVE_DELAY = 1000000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
}

const actionTypes = {
  ADD_TOAST: "ADD_TOAST",
  UPDATE_TOAST: "UPDATE_TOAST",
  DISMISS_TOAST: "DISMISS_TOAST",
  REMOVE_TOAST: "REMOVE_TOAST",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_SAFE_INTEGER
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType["ADD_TOAST"]
      toast: ToasterToast
    }
  | {
      type: ActionType["UPDATE_TOAST"]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType["DISMISS_TOAST"]
      toastId?: ToasterToast["id"]
    }
  | {
      type: ActionType["REMOVE_TOAST"]
      toastId?: ToasterToast["id"]
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const addToRemoveQueue = (toastId: string) => {
  if (toastTimeouts.has(toastId)) {
    return
  }

  const timeout = setTimeout(() => {
    toastTimeouts.delete(toastId)
    dispatch({
      type: "REMOVE_TOAST",
      toastId: toastId,
    })
  }, TOAST_REMOVE_DELAY)

  toastTimeouts.set(toastId, timeout)
}

export const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case "ADD_TOAST":
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case "UPDATE_TOAST":
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case "DISMISS_TOAST": {
      const { toastId } = action

      // ! Side effects ! - This could be extracted into a dismissToast() action,
      // but I'll keep it here for simplicity
      if (toastId) {
        addToRemoveQueue(toastId)
      } else {
        state.toasts.forEach((toast) => {
          addToRemoveQueue(toast.id)
        })
      }

      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === toastId || toastId === undefined
            ? {
                ...t,
                open: false,
              }
            : t
        ),
      }
    }
    case "REMOVE_TOAST":
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, "id">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: "UPDATE_TOAST",
      toast: { ...props, id },
    })
  const dismiss = () => dispatch({ type: "DISMISS_TOAST", toastId: id })

  dispatch({
    type: "ADD_TOAST",
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id: id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: "DISMISS_TOAST", toastId }),
  }
}

export { useToast, toast }


=== ./lib/prisma.ts ===
import { PrismaClient } from "@prisma/client";

const globalForPrisma = global as unknown as { prisma: PrismaClient };

export const prisma =
  globalForPrisma.prisma ||
  new PrismaClient({
    log: ["query"],
  });

if (process.env.NODE_ENV !== "production") globalForPrisma.prisma = prisma;


=== ./lib/firebase.ts ===
import { getStorage, ref, uploadBytes, getDownloadURL } from "firebase/storage";
import { app } from "./firebaseConfig"; // Make sure to create this file with your Firebase configuration

const storage = getStorage(app);

export async function uploadAudioToFirebase(audioBlob: Blob, sessionId: string): Promise<string> {
  const fileName = `audio_${sessionId}_${Date.now()}.mp3`;
  const storageRef = ref(storage, `recordings/${fileName}`);

  try {
    const snapshot = await uploadBytes(storageRef, audioBlob);
    const downloadURL = await getDownloadURL(snapshot.ref);
    return downloadURL;
  } catch (error) {
    console.error("Error uploading to Firebase:", error);
    throw error;
  }
}


=== ./lib/utils.ts ===
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}


=== ./lib/openai.ts ===
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export default openai;


=== ./lib/firebaseConfig.ts ===
// Import the functions you need from the SDKs you need
import { initializeApp } from "firebase/app";
// TODO: Add SDKs for Firebase products that you want to use
// https://firebase.google.com/docs/web/setup#available-libraries

// Your web app's Firebase configuration
const firebaseConfig = {
  apiKey: "AIzaSyCWdcidbfJOsiiLmK5-mGwi1Kr9XiJpcB4",
  authDomain: "confetto-f644d.firebaseapp.com",
  projectId: "confetto-f644d",
  storageBucket: "confetto-f644d.appspot.com",
  messagingSenderId: "30130562868",
  appId: "1:30130562868:web:ac2c34b56177cfdf87a761",
};

// Initialize Firebase
export const app = initializeApp(firebaseConfig);


=== ./lib/actions.ts ===
"use server";

import { revalidatePath } from "next/cache";
import { prisma } from "./prisma";
import { redirect } from "next/navigation";
import Replicate from "replicate";
import openai from "./openai";

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

export async function createMockSession(formData: FormData) {
  const questionId = formData.get("questionId");
  const userId = formData.get("userId");

  if (!questionId || typeof questionId !== "string" || !userId || typeof userId !== "string") {
    throw new Error("Invalid question ID or user ID");
  }

  const createdSession = await prisma.practiceSession.create({
    data: {
      userId: userId,
      questionId: questionId,
    },
  });

  const practiceSessionId = createdSession.id;

  revalidatePath("/create-session");
  redirect(`/session/${practiceSessionId}`); // Redirect to the specific session page after creation
}

export async function saveAudioUrl(url: string, sessionId: string) {
  try {
    const updatedSession = await prisma.practiceSession.update({
      where: { id: sessionId },
      data: { recordingUrl: url },
    });

    if (!updatedSession) {
      throw new Error("Failed to update session with audio URL");
    }

    // Transcribe the audio using Replicate
    const transcription = await transcribeAudio(url);

    // Update the session with the transcription
    await prisma.practiceSession.update({
      where: { id: sessionId },
      data: { recordingTranscription: transcription },
    });

    //let's get the quesiton
    const question = await prisma.question.findUnique({
      where: { id: updatedSession.questionId },
    });

    if (!question) {
      throw new Error("Failed to find question");
    }
    // Get feedback using the question and transcription
    const feedback = await getFeedbackFromLLM({
      question: question.content,
      answer: transcription,
    });

    // Create feedback based on the LLM response
    const createdFeedback = await prisma.feedback.create({
      data: {
        content: feedback || "null",
        practiceSessionId: sessionId,
      },
    });

    if (!createdFeedback) {
      throw new Error("Failed to create feedback");
    }

    revalidatePath(`/session/${sessionId}`);
    return {
      success: true,
      message: "Audio URL saved, transcribed, and feedback generated successfully",
    };
  } catch (error) {
    console.error("Error saving audio URL or transcribing:", error);
    return { success: false, message: "Failed to save audio URL or transcribe" };
  }
}

async function transcribeAudio(audioUrl: string): Promise<string> {
  try {
    const input = {
      audio: audioUrl,
      batch_size: 64,
    };

    const output = await replicate.run(
      "vaibhavs10/incredibly-fast-whisper:3ab86df6c8f54c11309d4d1f930ac292bad43ace52d10c80d87eb258b3c9f79c",
      { input }
    );

    if (typeof output === "object" && output !== null && "text" in output) {
      return output.text as string;
    }

    throw new Error("Unexpected output format from transcription API");
  } catch (error) {
    console.error("Error transcribing audio:", error);
    throw new Error("Failed to transcribe audio");
  }
}

async function getFeedbackFromLLM({ question, answer }: { question: string; answer: string }) {
  const prompt = `The following is a medical school interview practice session.

Please grade the answer out of 100 where the grading is broken down into 5 categories with the following weights:

1. Understanding of ethical principles (weight of 25)
2. Communication skills (weight of 20)
3. Professionalism and empathy (weight of 20)
4. Legal and medical legislation within the jurisdiction of Canada (weight of 15)
5. Organization and structure (weight of 20)

Additionally, please provide feedback, along with actionable insights.

The question is the following:

${question}

The answer is the following:

${answer}`;

  console.log("logging prompt", prompt);

  // TODO: Implement the actual call to the LLM API here
  // This function should return the LLM's response
  const response = await openai.chat.completions.create({
    model: "o1-preview",
    messages: [{ role: "user", content: prompt }],
  });

  return response.choices[0].message.content;
}

